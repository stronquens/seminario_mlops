{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1445089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/stronquens/Prueba/e/PRUEB-14\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import neptune.new as neptune\n",
    "import neptune.new.integrations.sklearn as npt_utils\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"stronquens/Prueba\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjNTY4YWQzZS1iZDE0LTRiYzItOWJlMy1jN2JiMDY4MmFlNGUifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": 90,\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 5,\n",
    "}\n",
    "run[\"parameters\"] = parameters\n",
    "\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=28743\n",
    ")\n",
    "\n",
    "\n",
    "gbc = GradientBoostingClassifier(**parameters, random_state=28743)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Neptune integration with scikit-learn works with\n",
    "# the regression and classification problems as well.\n",
    "# Check the user guide in the documentation for more details:\n",
    "# https://docs.neptune.ai/integrations-and-supported-tools/model-training/sklearn\n",
    "run[\"classifier\"] = npt_utils.create_classifier_summary(\n",
    "    gbc, X_train, X_test, y_train, y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f201a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8e0a351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805555555555555"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Añade la metrica acc\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "run['metrics/acc'] =  acc\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5edef9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade cualquier archivo\n",
    "#run[\"dataset/train\"].upload(\"./datasets/train/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a9573e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-4c86895da9e2>:3: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  np.fromstring(y_test)\n",
      "<ipython-input-73-4c86895da9e2>:6: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  run[\"dataset/X_train\"] = X_train.tostring()\n",
      "<ipython-input-73-4c86895da9e2>:7: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  run[\"dataset/X_test\"] =  X_test.tostring()\n",
      "<ipython-input-73-4c86895da9e2>:8: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  run[\"dataset/y_train\"] = y_train.tostring()\n",
      "<ipython-input-73-4c86895da9e2>:9: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  run[\"dataset/y_test\"] = y_test.tostring()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.fromstring(y_test)\n",
    "\n",
    "# Upload dataset TO DO\n",
    "run[\"dataset/X_train\"] = X_train.tostring()\n",
    "run[\"dataset/X_test\"] =  X_test.tostring()\n",
    "run[\"dataset/y_train\"] = y_train.tostring()\n",
    "run[\"dataset/y_test\"] = y_test.tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa17b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 79 operations to synchronize with Neptune. Do not kill this process.\n",
      "Error occurred during asynchronous operation processing: Max string attribute length (16384) exceeded (679926).\n",
      "Error occurred during asynchronous operation processing: Max string attribute length (16384) exceeded (2712675).\n",
      "Error occurred during asynchronous operation processing: Max string attribute length (16384) exceeded (22725).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 79 operations synced, thanks for waiting!\r\n"
     ]
    }
   ],
   "source": [
    "run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
